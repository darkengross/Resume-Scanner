{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import PDFMinerLoader, TextLoader, Docx2txtLoader\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain_community.llms import Cohere\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import datetime, json, os, tiktoken\n",
    "from IPython.display import Markdown\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSISTANT_LANGUAGE = \"english\"\n",
    "cohere_api_key = 'v7yOHn61izIiMkGllF2gzbM5e0PHnDEwa7fjh38E'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Khushal Goyal\\nB.Tech\\n+91 7610513661\\nMail: khushalgoyal77@gmail.com\\nlinkedin:https://www.linkedin.com/in/khushal-goyal-a27b54227/\\nGithub: https://github.com/darkengross\\nPortfolio: https://portfolio-v2-nine-mauve.vercel.app/\\nEDUCATION\\n\\nThe LNM Institute of Information Technology\\nAaradhan public school\\nCarmel convent Sr. Sec. School\\n\\nINTERNSHIPS\\n\\nAgent Oriented Development | LNMIIT\\n\\nB.Tech in Computer Science | GPA : 7.63/10\\n\\nclass XII | Percentage : 93/100\\n\\nclass X | Percentage : 93/100\\n\\nNovember 2021 – Present\\n\\nJune 2023 – July 2023\\n\\n– Developed Algorithms for multiagent systems.\\n– Documented more than 22 research papers on heuristic, reinforcement learning based drone navigation algorithms\\n\\nTECHNICAL SKILLS\\n\\nLanguages :Python, C/C++, SQL, HTML, CSS, Java\\nFrameworks :PyTorch, TensorFlow, Keras, HuggingFace, Transformers, NLTK, Spacy, Power BI\\nDevOps and API Tools : Git, Docker,Postman\\nOthers : Data Structures, SOLID Principles, Design Patterns, Multiagent systems, machine learning, deep learning, reinforcement\\nlearning, Data Science\\n\\nPROJECTS\\n\\nMulti class Classification Using Image transformers | Transformers, PyTorch, Transformers\\n\\nMarch 2024\\n\\n– An image classification model built with a transformer encoder only architecture.\\n– Developed a PyTorch model, achieving 75% accuracy; improved to 95% with transfer learning and fine-tuning a pretrained\\n\\nvision transformer.\\n\\nLoksabha 2024 data analysis: Instagram | Python, Data Gathering, Data Visualizing, data Inferencing\\n\\nApril 2024\\n\\n– Research on Instagram data of Loksabha 2024\\n– Data is fetched from meta’s crowdtangle API and is analysed using Unsupervised learning algorithms like HDBSCAN, topic\\n\\nmodelling using LDA and BertTopic\\n\\nAnime Face Generator | GAN, Deep Learning, Data Science\\n\\nJan 2024\\n\\n– using Generative Adversarial Networks (GAN) to create a generative model\\n– The Model takes input a value and corresponding to that generate a face image of an anime Character\\n\\nASL Convertor | Python, Data Analysis, Machine Learning\\n– American sign language(ASL) recognition system\\n– Explored multiple algorithms to classify and compare the American Sign Language dataset from Kaggle, achieving\\n\\nJune 2023\\n\\naccuracies from 74% to 95%.\\n\\nPOSITION OF RESPONSIBILITY\\nHead | SocioTech Podcast\\n\\n– Head of the Sociotech podcast team under CMLBDA, LNMIIT\\n\\nVolunteer Engagement Executive | BloodConnect Jaipur\\n\\n– Managed a team of more than 30 people in organizing blood camps, awareness sessions, skits, etc.\\n\\nCERTIfiCATIONS\\n\\nVolunteer Engagement Executive | BloodConnect Jaipur\\n\\n– LOR/Certificate for performing social work in making India blood sufficient.\\n\\nIBM Data Analysis | IBM, Coursera\\n\\n– For compeleting IBM data Analyst Course\\n\\nAutomatic Birthday Generation App | LNMIIT, Jaipur\\n\\n– Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\\n\\nHOBBIES\\n\\nPodcasting, Learning different spoken languages, Cooking\\n\\nJan 2024\\n\\nFeb 2023\\n\\nJan 2024\\n\\nAug 2023\\n\\nAug 2023', metadata={'source': './data/resume/Khushal_ml.pdf', 'doc_number': 0})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def langchain_document_loader(file_path):\n",
    "    \"\"\"Load and split a PDF file in Langchain.\n",
    "    Parameters:\n",
    "        - file_path (str): path of the file.\n",
    "    Output:\n",
    "        - documents: list of Langchain Documents.\"\"\"\n",
    "\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        loader = PDFMinerLoader(file_path=file_path)\n",
    "    else:\n",
    "        print(\"You can only upload .pdf files!\")\n",
    "\n",
    "    # 1. Load and split documents\n",
    "    documents = loader.load_and_split()\n",
    "\n",
    "    # 2. Update the metadata: add document number to metadata\n",
    "    for i in range(len(documents)):\n",
    "        documents[i].metadata = {\n",
    "            \"source\": documents[i].metadata[\"source\"],\n",
    "            \"doc_number\": i,\n",
    "        }\n",
    "\n",
    "    return documents\n",
    "\n",
    "documents = langchain_document_loader(\"./data/resume/Khushal_ml.pdf\")\n",
    "print(\"number of documents:\",len(documents))\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_embeddings_model(LLM_service=\"llama3.1\"):\n",
    "    \"\"\"Connect to the embeddings API endpoint by specifying the name of the embedding model.\"\"\"\n",
    "    if LLM_service == \"OpenAI\":\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model='gpt-3.5-turbo',\n",
    "            api_key=openai_api_key)\n",
    "\n",
    "    if LLM_service == \"llama3.1\":\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            model=\"llama3.1\"\n",
    "        )\n",
    "    return embeddings\n",
    "   \n",
    "# embeddings_OpenAI = select_embeddings_model(LLM_service=\"OpenAI\")\n",
    "# embeddings_google = select_embeddings_model(LLM_service=\"Google\")\n",
    "embeddings_ollama = select_embeddings_model(LLM_service='llama3.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(embeddings, documents):\n",
    "    vector_store = FAISS.from_documents(documents=documents, embedding=embeddings)\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "vector_store_ollama = create_vectorstore(embeddings_ollama, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorstore_backed_retriever(vectorstore, search_type = 'similarity', k = 5, score_threshold = None):\n",
    "    search_kwargs = {}\n",
    "    if k is not None:\n",
    "        search_kwargs['k'] = k\n",
    "    if score_threshold is not None:\n",
    "        search_kwargs['score_threshold'] = score_threshold\n",
    "        \n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type = search_type,\n",
    "        search_kwargs = search_kwargs\n",
    "    )\n",
    "    \n",
    "    return retriever\n",
    "\n",
    "base_retriever_ollama = vectorstore_backed_retriever(vector_store_ollama, \"similarity\", k = min(4, len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CohereRerank_retriever(base_retriever, cohere_api_key, cohere_model = 'rerank-multilingual-v2.0', top_n=2):\n",
    "    compressor = CohereRerank(\n",
    "        cohere_api_key=cohere_api_key, \n",
    "        model=cohere_model, \n",
    "        top_n=top_n\n",
    "    )\n",
    "\n",
    "    retriever_Cohere = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor,\n",
    "        base_retriever=base_retriever\n",
    "    )\n",
    "    \n",
    "    return retriever_Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_Cohere_ollama = CohereRerank_retriever(\n",
    "    base_retriever=base_retriever_ollama, \n",
    "    cohere_api_key=cohere_api_key,\n",
    "    cohere_model=\"rerank-multilingual-v2.0\",  \n",
    "    top_n=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown field: parameter model is not a valid field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar doc id : 0 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"Extract the job title and company name of the first work experience.\"\n",
    "\n",
    "most_relevant_docs = retriever_Cohere_ollama.get_relevant_documents(query)\n",
    "\n",
    "for i in range(len(most_relevant_docs)):\n",
    "    print(f\"\"\"Most similar doc id : {most_relevant_docs[i].metadata['doc_number']} \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_LLM(LLM_provider,api_key,temperature=0.5,top_p=0.95,model_name=None):\n",
    "    \"\"\"Instantiate LLM in Langchain.\n",
    "    Parameters:\n",
    "        LLM_provider (str): the LLM provider; in [\"OpenAI\",\"Google\",\"HuggingFace\"]\n",
    "        model_name (str): in [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-0125\", \"gpt-4-turbo-preview\", \n",
    "            \"gemini-pro\", \"mistralai/Mistral-7B-Instruct-v0.2\"].            \n",
    "        api_key (str): google_api_key or openai_api_key or huggingfacehub_api_token \n",
    "        temperature (float): Range: 0.0 - 1.0; default = 0.5\n",
    "        top_p (float): : Range: 0.0 - 1.0; default = 1.\n",
    "    \"\"\"\n",
    "    if LLM_provider == \"OpenAI\":\n",
    "        llm = ChatOpenAI(\n",
    "            api_key=api_key,\n",
    "            model=model_name,\n",
    "            temperature=temperature,\n",
    "            model_kwargs={\n",
    "                \"top_p\": top_p\n",
    "            }\n",
    "        )\n",
    "    if LLM_provider == \"ollama\":\n",
    "        llm = ChatOllama(\n",
    "            model=model_name,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            convert_system_message_to_human=True\n",
    "        )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_LLM_and_retriever(provider=\"ollama\",model_name=\"llama3.1\",temperature=0.0,top_p=0.95):\n",
    "    if provider==\"OpenAI\":\n",
    "        llm = instantiate_LLM(\n",
    "            \"OpenAI\",\n",
    "            api_key=openai_api_key,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            model_name=model_name\n",
    "        )\n",
    "        retriever = retriever_Cohere_openAI\n",
    "    else: # \"Google\"\n",
    "        llm = instantiate_LLM(\n",
    "            LLM_provider=\"ollama\",\n",
    "            temperature=temperature,\n",
    "            api_key = \"\",\n",
    "            top_p=top_p, \n",
    "            model_name=model_name\n",
    "        )\n",
    "        retriever = retriever_Cohere_ollama\n",
    "        \n",
    "    return llm,retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm,retriever = set_LLM_and_retriever(provider=\"ollama\",temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#                 Prompt Templates\n",
    "#####################################################\n",
    "\n",
    "templates = {}\n",
    "\n",
    "# 2.1 Contact information Section\n",
    "templates[\n",
    "    \"Contact__information\"\n",
    "] = \"\"\"Extract and evaluate the contact information. \\\n",
    "Output a dictionary with the following keys:\n",
    "- candidate__name \n",
    "- candidate__title\n",
    "- candidate__location\n",
    "- candidate__email\n",
    "- candidate__phone\n",
    "- candidate__social_media: Extract a list of all social media profiles, blogs or websites.\n",
    "- evaluation__ContactInfo: Evaluate in {language} the contact information.\n",
    "- score__ContactInfo: Rate the contact information by giving a score (integer) from 0 to 100.\n",
    "\"\"\"\n",
    "\n",
    "# 2.2. Summary Section\n",
    "templates[\n",
    "    \"CV__summary\"\n",
    "] = \"\"\"Extract the summary and/or objective section. This is a separate section of the resume. \\\n",
    "If the resume doed not contain a summary and/or objective section, then simply write \"unknown\".\"\"\"\n",
    "\n",
    "# 2.3. WORK Experience Section\n",
    "\n",
    "templates[\n",
    "    \"Work__experience\"\n",
    "] = \"\"\"Extract all work experiences. For each work experience: \n",
    "1. Extract the job title.\n",
    "2. Extract the company.  \n",
    "3. Extract the start date and output it in the following format: \\\n",
    "YYYY/MM/DD or YYYY/MM or YYYY (depending on the availability of the day and month).\n",
    "4. Extract the end date and output it in the following format: \\\n",
    "YYYY/MM/DD or YYYY/MM or YYYY (depending on the availability of the day and month).\n",
    "5. Output a dictionary with the following keys: job__title, job__company, job__start_date, job__end_date.\n",
    "\n",
    "Format your response as a list of dictionaries.\n",
    "\"\"\"\n",
    "\n",
    "# 2.4. Projects Section\n",
    "templates[\n",
    "    \"CV__Projects\"\n",
    "] = \"\"\"Include any side projects outside the work experience. \n",
    "For each project:\n",
    "1. Extract the title of the project. \n",
    "2. Extract the start date and output it in the following format: \\\n",
    "YYYY/MM/DD or YYYY/MM or YYYY (depending on the availability of the day and month).\n",
    "3. Extract the end date and output it in the following format: \\\n",
    "YYYY/MM/DD or YYYY/MM or YYYY (depending on the availability of the day and month).\n",
    "4. Output a dictionary with the following keys: project__title, project__start_date, project__end_date.\n",
    "\n",
    "Format your response as a list of dictionaries.\n",
    "\"\"\"\n",
    "\n",
    "# 2.5. Education Section\n",
    "templates[\n",
    "    \"CV__Education\"\n",
    "] = \"\"\"Extract all educational background and academic achievements.\n",
    "For each education achievement:\n",
    "1. Extract the name of the college or the high school. \n",
    "2. Extract the earned degree. Honors and achievements are included.\n",
    "3. Extract the start date and output it in the following format: \\\n",
    "YYYY/MM/DD or YYYY/MM or YYYY (depending on the availability of the day and month).\n",
    "4. Extract the end date and output it in the following format: \\\n",
    "YYYY/MM/DD or YYYY/MM or YYYY (depending on the availability of the day and month).\n",
    "5. Output a dictionary with the following keys: edu__college, edu__degree, edu__start_date, edu__end_date.\n",
    "\n",
    "Format your response as a list of dictionaries.\n",
    "\"\"\"\n",
    "\n",
    "templates[\n",
    "    \"Education__evaluation\"\n",
    "] = \"\"\"Your task is to perform the following actions:  \n",
    "1. Rate the quality of the Education section by giving an integer score from 0 to 100. \n",
    "2. Evaluate (in three sentences and in {language}) the quality of the Education section.\n",
    "3. Output a dictionary with the following keys: score__edu, evaluation__edu.\n",
    "\"\"\"\n",
    "\n",
    "# 2.6. Skills\n",
    "templates[\n",
    "    \"candidate__skills\"\n",
    "] = \"\"\"Extract the list of soft and hard skills from the skill section. Output a list.\n",
    "The skill section is a separate section.\n",
    "\"\"\"\n",
    "\n",
    "templates[\n",
    "    \"Skills__evaluation\"\n",
    "] = \"\"\"Your task is to perform the following actions: \n",
    "1. Rate the quality of the Skills section by giving an integer score from 0 to 100.\n",
    "2. Evaluate (in three sentences and in {language}) the quality of the Skills section.\n",
    "3. Output a dictionary with the following keys: score__skills, evaluation__skills.\n",
    "\"\"\"\n",
    "\n",
    "# 2.7. Languages\n",
    "templates[\n",
    "    \"CV__Languages\"\n",
    "] = \"\"\"Extract all the languages that the candidate can speak. For each language:\n",
    "1. Extract the language.\n",
    "2. Extract the fluency. If the fluency is not available, then simply write \"unknown\".\n",
    "3. Output a dictionary with the following keys: spoken__language, language__fluency.\n",
    "\n",
    "Format your response as a list of dictionaries.\n",
    "\"\"\"\n",
    "\n",
    "templates[\n",
    "    \"Languages__evaluation\"\n",
    "] = \"\"\" Your task is to perform the following actions: \n",
    "1. Rate the quality of the language section by giving an integer score from 0 to 100.\n",
    "2. Evaluate (in three sentences and in {language}) the quality of the language section.\n",
    "3. Output a dictionary with the following keys: score__language,evaluation__language.\n",
    "\"\"\"\n",
    "\n",
    "# 2.8. Certifications\n",
    "templates[\n",
    "    \"CV__Certifications\"\n",
    "] = \"\"\"Extraction of all certificates other than education background and academic achievements. \\\n",
    "For each certificate: \n",
    "1. Extract the title of the certification. \n",
    "2. Extract the name of the organization or institution that issues the certification.\n",
    "3. Extract the date of certification and output it in the following format: \\\n",
    "YYYY/MM/DD or YYYY/MM or YYYY (depending on the availability of the day and month).\n",
    "4. Extract the certification expiry date and output it in the following format: \\\n",
    "YYYY/MM/DD or YYYY/MM or YYYY (depending on the availability of the day and month).\n",
    "5. Extract any other information listed about the certification. if not found, then simply write \"unknown\".\n",
    "6. Output a dictionary with the following keys: certif__title, certif__organization, certif__date, certif__expiry_date, certif__details.\n",
    "\n",
    "Format your response as a list of dictionaries.\n",
    "\"\"\"\n",
    "\n",
    "templates[\n",
    "    \"Certif__evaluation\"\n",
    "] = \"\"\"Your task is to perform the following actions: \n",
    "1. Rate the certifications by giving an integer score from 0 to 100.\n",
    "2. Evaluate (in three sentences and in {language}) the certifications and the quality of the text.\n",
    "3. Format your response as a dictionary with the following keys: score__certif,evaluation__certif.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 3. PROMPTS\n",
    "\n",
    "PROMPT_IMPROVE_SUMMARY = \"\"\"Your are given a resume (delimited by <resume></resume>) \\\n",
    "and a summary (delimited by <summary></summary>).\n",
    "1. In {language}, evaluate the summary (format and content) .\n",
    "2. Rate the summary by giving an integer score from 0 to 100. \\\n",
    "If the summary is \"unknown\", the score is 0.\n",
    "3. In {language}, strengthen the summary. The summary should not exceed 5 sentences. \\\n",
    "If the summary is \"unknown\", generate a strong summary in {language} with no more than 5 sentences. \\\n",
    "Please include: years of experience, top skills and experiences, some of the biggest achievements, and finally an attractive objective.\n",
    "4. Format your response as a dictionary with the following keys: evaluation__summary, score__summary, CV__summary_enhanced.\n",
    "\n",
    "<summary>\n",
    "{summary}\n",
    "</summary>\n",
    "------\n",
    "<resume>\n",
    "{resume}\n",
    "</resume>\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_IMPROVE_WORK_EXPERIENCE = \"\"\"you are given a work experience text delimited by triple backticks.\n",
    "1. Rate the quality of the work experience text by giving an integer score from 0 to 100. \n",
    "2. Suggest in {language} how to make the work experience text better and stronger.\n",
    "3. Strengthen the work experience text to make it more appealing to a recruiter in {language}. \\\n",
    "Provide additional details on responsibilities and quantify results for each bullet point. \\\n",
    "Format your text as a string in {language}.\n",
    "4. Format your response as a dictionary with the following keys: \"Score__WorkExperience\", \"Comments__WorkExperience\" and \"Improvement__WorkExperience\".\n",
    "\n",
    "Work experience text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_IMPROVE_PROJECT = \"\"\"you are given a project text delimited by triple backticks.\n",
    "1. Rate the quality of the project text by giving an integer score from 0 to 100. \n",
    "2. Suggest in {language} how to make the project text better and stronger.\n",
    "3. Strengthen the project text to make it more appealing to a recruiter in {language}, \\\n",
    "including the problem, the approach taken, the tools used and quantifiable results. \\\n",
    "Format your text as a string in {language}.\n",
    "4. Format your response as a dictionary with the following keys: Score__project, Comments__project, Improvement__project.\n",
    "\n",
    "project text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_EVALUATE_RESUME = \"\"\"You are given a resume delimited by triple backticks. \n",
    "1. Provide an overview of the resume in {language}.\n",
    "2. Provide a comprehensive analysis of the three main strengths of the resume in {language}. \\\n",
    "Format the top 3 strengths as string containg three bullet points.\n",
    "3. Provide a comprehensive analysis of the three main weaknesses of the resume in {language}. \\\n",
    "Format the top 3 weaknesses as string containg three bullet points.\n",
    "4. Format your response as a dictionary with the following keys: resume_cv_overview, top_3_strengths, top_3_weaknesses.\n",
    "\n",
    "The strengths and weaknesses lie in the format, style and content of the resume.\n",
    "\n",
    "Resume: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_template(resume_sections, language=ASSISTANt_LANGUAGE):\n",
    "    \"\"\"Create the promptTemplate for selected resume sections.\n",
    "    Parameters:\n",
    "       resume_sections (list): List of resume sections from which information will be extracted.\n",
    "       language (str): the language of the AI assistant.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the final template: Add the templates from the 'templates' dictionary where keys = resume_sections\n",
    "    template = f\"\"\"For the following resume delimited by triple backticks, output in {language} the following information:\\n\\n\"\"\"\n",
    "\n",
    "    for key in resume_sections:\n",
    "        template += key + \": \" + templates[key] + \"\\n---------\\n\\n\"\n",
    "\n",
    "    template += \"For any requested information, if it is not found, output 'unknown'.\\n\\n\"\n",
    "    template += (\n",
    "        \"\"\"Format the final output as a json dictionary with the following keys: (\"\"\"\n",
    "    )\n",
    "\n",
    "    for key in resume_sections:\n",
    "        template += \"\" + key + \", \"\n",
    "    template = template[:-2] + \")\"  # remove the last \", \"\n",
    "\n",
    "    template += \"\"\"\\n\\nResume: ```{text}```\"\"\"\n",
    "\n",
    "    # Create the PromptTemplate\n",
    "    prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**LLM prompt example:**\n",
      "\n",
      "For the following resume delimited by triple backticks, output in english the following information:\n",
      "\n",
      "Contact__information: Extract and evaluate the contact information. Output a dictionary with the following keys:\n",
      "- candidate__name \n",
      "- candidate__title\n",
      "- candidate__location\n",
      "- candidate__email\n",
      "- candidate__phone\n",
      "- candidate__social_media: Extract a list of all social media profiles, blogs or websites.\n",
      "- evaluation__ContactInfo: Evaluate in english the contact information.\n",
      "- score__ContactInfo: Rate the contact information by giving a score (integer) from 0 to 100.\n",
      "\n",
      "---------\n",
      "\n",
      "CV__summary: Extract the summary and/or objective section. This is a separate section of the resume. If the resume doed not contain a summary and/or objective section, then simply write \"unknown\".\n",
      "---------\n",
      "\n",
      "Work__experience: Extract all work experiences. For each work experience: \n",
      "1. Extract the job title.\n",
      "2. Extract the company.  \n",
      "3. Extract the start date and output it in the following format: YYYY/MM/DD or YYYY/MM or YYYY (depending on the availability of the day and month).\n",
      "4. Extract the end date and output it in the following format: YYYY/MM/DD or YYYY/MM or YYYY (depending on the availability of the day and month).\n",
      "5. Output a dictionary with the following keys: job__title, job__company, job__start_date, job__end_date.\n",
      "\n",
      "Format your response as a list of dictionaries.\n",
      "\n",
      "---------\n",
      "\n",
      "For any requested information, if it is not found, output 'unknown'.\n",
      "\n",
      "Format the final output as a json dictionary with the following keys: (Contact__information, CV__summary, Work__experience)\n",
      "\n",
      "Resume: ```...```\n"
     ]
    }
   ],
   "source": [
    "# Here is a example:\n",
    "\n",
    "prompt_template = create_prompt_template(\n",
    "    ['Contact__information','CV__summary','Work__experience'],\n",
    "    language=ASSISTANT_LANGUAGE\n",
    ")\n",
    "\n",
    "print(\"\\n**LLM prompt example:**\\n\")\n",
    "# Format the PromptTemplate\n",
    "prompt = prompt_template.format_prompt(text=\"...\",language=ASSISTANt_LANGUAGE).text\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_LLM(\n",
    "    llm,\n",
    "    documents,\n",
    "    resume_sections: list,\n",
    "    info_message=\"\",\n",
    "    language=ASSISTANT_LANGUAGE,\n",
    "):\n",
    "    \"\"\"Invoke LLM and get a response.\n",
    "    Parameters:\n",
    "     - llm: the LLM to call\n",
    "     - documents: the Langchain Documents. \n",
    "     - resume_sections (list): List of resume sections to be parsed.\n",
    "     - info_message (str): display an informational message.\n",
    "     - language (str): the assistant language. \n",
    "\n",
    "     Output:\n",
    "     - response_content (str): the content of the LLM response.\n",
    "     - response_tokens_count (int): count of response tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    now = (datetime.datetime.now()).strftime(\"%H:%M:%S\")\n",
    "    print(f\"**{now}** \\t{info_message}\")  \n",
    "\n",
    "    # 1. Create the promptTemplate.\n",
    "    prompt_template = create_prompt_template(\n",
    "        resume_sections,\n",
    "        language=language,\n",
    "    )\n",
    "\n",
    "    # 2. Format the PromptTemplate \n",
    "    if language is not None:\n",
    "        prompt = prompt_template.format_prompt(text=documents, language=language).text\n",
    "    else:\n",
    "        prompt = prompt_template.format_prompt(text=documents).text\n",
    "\n",
    "    # 3. Invoke the LLM\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    response_content = response.content[\n",
    "        response.content.find(\"{\") : response.content.rfind(\"}\") + 1\n",
    "    ]\n",
    "\n",
    "\n",
    "    return response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**19:32:04** \tExtract and evaluate contact information...\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 2min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'candidate_name': 'Khushal Goyal',\n",
       " 'candidate_title': 'B.Tech',\n",
       " 'candidate_location': 'unknown',\n",
       " 'candidate_email': 'khushalgoyal77@gmail.com',\n",
       " 'candidate_phone': '+91 7610513661',\n",
       " 'candidate_social_media': [{'platform': 'LinkedIn',\n",
       "   'url': 'https://www.linkedin.com/in/khushal-goyal-a27b54227/'},\n",
       "  {'platform': 'GitHub', 'url': 'https://github.com/darkengross'},\n",
       "  {'platform': 'Portfolio',\n",
       "   'url': 'https://portfolio-v2-nine-mauve.vercel.app/'}],\n",
       " 'evaluation_ContactInfo': 'The contact information provided is sufficient for professional purposes.',\n",
       " 'score_ContactInfo': 80}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##########################################################################################################\n",
    "#     CONTACT_INFORMATION: Name, Title, Location, Email, Phone number and Social media profiles.\n",
    "##########################################################################################################\n",
    "\n",
    "try:\n",
    "    response_content = invoke_LLM(\n",
    "        llm,\n",
    "        documents,\n",
    "        resume_sections=[\"Contact__information\"],\n",
    "        info_message=\"Extract and evaluate contact information...\",\n",
    "        language=ASSISTANT_LANGUAGE,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Load response_content into json dictionary\n",
    "        CONTACT_INFORMATION = json.loads(response_content, strict=False)\n",
    "    except Exception as e:\n",
    "        print(\"[ERROR] json.loads returns error:\", e)\n",
    "        CONTACT_INFORMATION = {}\n",
    "        \n",
    "except Exception as error:\n",
    "    print(\"[ERROR]:\", error)\n",
    "    CONTACT_INFORMATION = {}\n",
    "    \n",
    "CONTACT_INFORMATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_text(text,start_tag,end_tag=None):\n",
    "    \"\"\"Use start and end tags to extract a substring from text.\"\"\"\n",
    "    start_index = text.find(start_tag)\n",
    "    if end_tag is None:\n",
    "        extacted_txt = text[start_index+len(start_tag):]\n",
    "    else:\n",
    "        end_index = text.find(end_tag) \n",
    "        extacted_txt = text[start_index+len(start_tag):end_index]\n",
    "    \n",
    "    return extacted_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_contact_information(llm, documents):\n",
    "    \"\"\"Extract Contact Information: Name, Title, Location, Email, Phone number and Social media profiles.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response_content= invoke_LLM(\n",
    "            llm,\n",
    "            documents,\n",
    "            resume_sections=[\"Contact__information\"],\n",
    "            info_message=\"Extract and evaluate contact information...\",\n",
    "            language=ASSISTANT_LANGUAGE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # Load response_content into json dictionary\n",
    "            CONTACT_INFORMATION = json.loads(response_content, strict=False)\n",
    "        except Exception as e:\n",
    "            print(\"[ERROR] json.loads returns error:\", e)\n",
    "            print(\"\\n['INFO'] Parse response content...\\n\")\n",
    "            list_fields = [{'Contact__information':\n",
    "                            ['candidate__name','candidate__title','candidate__location',\n",
    "                             'candidate__email','candidate__phone','candidate__social_media',\n",
    "                             'evaluation__ContactInfo','score__ContactInfo']\n",
    "                           }]\n",
    "            list_rfind = [\",\\n\",\",\\n\",\",\\n\",\",\\n\",\",\\n\",\",\\n\",\",\\n\",\",\\n\",\"}\\n\"]\n",
    "            list_exclude_first_car = [True,True,True,True,True,True,False,True,False]\n",
    "            CONTACT_INFORMATION = ResponseContent_Parser(response_content,list_fields,list_rfind,list_exclude_first_car)\n",
    "            # Convert the score to int\n",
    "            try:\n",
    "                CONTACT_INFORMATION[\"Contact__information\"][\"score__ContactInfo\"] = int(\n",
    "                    CONTACT_INFORMATION[\"Contact__information\"][\"score__ContactInfo\"]\n",
    "                )\n",
    "            except:\n",
    "                CONTACT_INFORMATION[\"Contact__information\"][\"score__ContactInfo\"] = -1\n",
    "\n",
    "    except Exception as exception:\n",
    "        print(f\"[Error] {exception}\")\n",
    "        CONTACT_INFORMATION = {\n",
    "            \"Contact__information\": {\n",
    "                \"candidate__name\": \"unknown\",\n",
    "                \"candidate__title\": \"unknown\",\n",
    "                \"candidate__location\": \"unknown\",\n",
    "                \"candidate__email\": \"unknown\",\n",
    "                \"candidate__phone\": \"unknown\",\n",
    "                \"candidate__social_media\": \"unknown\",\n",
    "                \"evaluation__ContactInfo\": \"unknown\",\n",
    "                \"score__ContactInfo\": -1,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    return CONTACT_INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**20:08:46** \tExtract and evaluate contact information...\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 2min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'candidate_name': 'Khushal Goyal',\n",
       " 'candidate_title': 'B.Tech',\n",
       " 'candidate_location': 'unknown',\n",
       " 'candidate_email': 'khushalgoyal77@gmail.com',\n",
       " 'candidate_phone': '+91 7610513661',\n",
       " 'candidate_social_media': ['LinkedIn: https://www.linkedin.com/in/khushal-goyal-a27b54227/',\n",
       "  'GitHub: https://github.com/darkengross',\n",
       "  'Portfolio: https://portfolio-v2-nine-mauve.vercel.app/'],\n",
       " 'evaluation_ContactInfo': 'The contact information is well-structured and includes a professional email address, phone number, and social media profiles.',\n",
       " 'score_ContactInfo': 90}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "CONTACT_INFORMATION = Extract_contact_information(llm,documents)\n",
    "CONTACT_INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Evaluate_Summary(llm, documents):\n",
    "    \"\"\"Extract, evaluate and strengthen the summary.\"\"\"\n",
    "\n",
    "    # 1. Extract the summary\n",
    "    ######################################\n",
    "    try:\n",
    "        response_content = invoke_LLM(\n",
    "            llm,\n",
    "            documents,\n",
    "            resume_sections=[\"CV__summary\" ],\n",
    "            info_message=\"Extract and evaluate the Summary....\",\n",
    "            language=ASSISTANT_LANGUAGE,\n",
    "        )\n",
    "        print(\"summary response:\\n\", response_content)\n",
    "        try:\n",
    "            # Load response_content into json dictionary\n",
    "            SUMMARY_SECTION = json.loads(response_content, strict=False)\n",
    "        except Exception as e:\n",
    "            print(\"[ERROR] json.loads returns error:\", e)\n",
    "            print(\"\\n['INFO'] Parse response content...\\n\")\n",
    "            \n",
    "            list_fields = [\"CV__summary\"]\n",
    "            list_rfind = [\"}\\n\"]\n",
    "            list_exclude_first_car = [True]\n",
    "            SUMMARY_SECTION = ResponseContent_Parser(\n",
    "                response_content, list_fields, list_rfind, list_exclude_first_car\n",
    "            )\n",
    "\n",
    "    except Exception as exception:\n",
    "        print(f\"[Error] {exception}\")\n",
    "        SUMMARY_SECTION = {\"CV__summary\": \"unknown\"}\n",
    "\n",
    "    # 2. Evaluate and improve the summary\n",
    "    #############################################\n",
    "\n",
    "    try:\n",
    "        prompt_template = PromptTemplate.from_template(PROMPT_IMPROVE_SUMMARY)\n",
    "\n",
    "        prompt = prompt_template.format_prompt(\n",
    "            resume=documents,\n",
    "            language=ASSISTANT_LANGUAGE,\n",
    "            summary=SUMMARY_SECTION[\"CV__summary\"],\n",
    "        ).text\n",
    "\n",
    "        # Invoke LLM\n",
    "        response = llm.invoke(prompt)\n",
    "        response_content = response.content[\n",
    "            response.content.find(\"{\") : response.content.rfind(\"}\") + 1\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            SUMMARY_EVAL = {}\n",
    "            SUMMARY_EVAL[\"Summary__evaluation\"] = json.loads(response_content, strict=False)\n",
    "        except Exception as e:\n",
    "            print(\"[ERROR] json.loads returns error:\", e)\n",
    "            print(\"\\n['INFO'] Parse response content...\\n\")\n",
    "            list_fields = [\n",
    "                \"evaluation__summary\",\n",
    "                \"score__summary\",\n",
    "                \"CV__summary_enhanced\",\n",
    "            ]\n",
    "            list_rfind = [\",\\n\", \",\\n\", \"}\\n\"]\n",
    "            list_exclude_first_car = [True, False, True]\n",
    "            SUMMARY_EVAL[\"Summary__evaluation\"] = ResponseContent_Parser(\n",
    "                response_content, list_fields, list_rfind, list_exclude_first_car\n",
    "            )\n",
    "            # Convert score to int\n",
    "            try:\n",
    "                SUMMARY_EVAL[\"Summary__evaluation\"][\"score__summary\"] = int(\n",
    "                    SUMMARY_EVAL[\"Summary__evaluation\"][\"score__summary\"]\n",
    "                )\n",
    "            except:\n",
    "                SUMMARY_EVAL[\"Summary__evaluation\"][\"score__summary\"] = -1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        SUMMARY_EVAL = {\n",
    "            \"Summary__evaluation\": {\n",
    "                \"evaluation__summary\": \"unknown\",\n",
    "                \"score__summary\": -1,\n",
    "                \"CV__summary_enhanced\": \"unknown\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "    SUMMARY_EVAL[\"CV__summary\"] = SUMMARY_SECTION[\"CV__summary\"]\n",
    "\n",
    "\n",
    "    return SUMMARY_EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**19:41:12** \tExtract and evaluate the Summary....\n",
      "[Error] too many values to unpack (expected 2)\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 3min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Summary__evaluation': {'evaluation__summary': \"The summary section of this resume appears to be empty, as indicated by the value 'unknown'.\",\n",
       "  'score__summary': 0,\n",
       "  'CV__summary_enhanced': {'summary': 'As a highly motivated and detail-oriented B.Tech in Computer Science graduate from LNMIIT, I bring 2+ years of experience in developing algorithms for multiagent systems, machine learning, and deep learning. My top skills include Python, C/C++, SQL, HTML, CSS, Java, PyTorch, TensorFlow, Keras, HuggingFace, Transformers, NLTK, Spacy, Power BI, Git, Docker, Postman, Data Structures, SOLID Principles, Design Patterns, Multiagent systems, machine learning, deep learning, and reinforcement learning. With a strong background in data science and analysis, I have achieved notable results in projects such as multi-class classification using image transformers, Loksabha 2024 data analysis, Anime Face Generator, ASL Convertor, and Automatic Birthday Generation App. As the Head of the Sociotech podcast team under CMLBDA, LNMIIT, and Volunteer Engagement Executive at BloodConnect Jaipur, I have demonstrated my ability to lead teams and manage projects effectively. My objective is to leverage my skills and experience to contribute to innovative projects that drive positive change.',\n",
       "   'years_of_experience': 2,\n",
       "   'top_skills': ['Python',\n",
       "    'C/C++',\n",
       "    'SQL',\n",
       "    'HTML',\n",
       "    'CSS',\n",
       "    'Java',\n",
       "    'PyTorch',\n",
       "    'TensorFlow',\n",
       "    'Keras',\n",
       "    'HuggingFace',\n",
       "    'Transformers',\n",
       "    'NLTK',\n",
       "    'Spacy',\n",
       "    'Power BI'],\n",
       "   'notable_achievements': ['Developed algorithms for multiagent systems',\n",
       "    'Achieved 95% accuracy in multi-class classification using image transformers',\n",
       "    'Analyzed Instagram data of Loksabha 2024 using unsupervised learning algorithms'],\n",
       "   'objective': 'To leverage my skills and experience to contribute to innovative projects that drive positive change.'}},\n",
       " 'CV__summary': 'unknown'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SUMMARY_EVAL = Extract_Evaluate_Summary(llm,documents)\n",
    "SUMMARY_EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**20:30:49** \tExtract and evaluate education section...\n",
      "[ERROR] json.loads returns error: Extra data: line 6 column 6 (char 208)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n        \"edu__college\": \"The LNM Institute of Information Technology\",\\n        \"edu__degree\": \"B.Tech in Computer Science\",\\n        \"edu__start_date\": \"June 2023\",\\n        \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n        \"edu__college\": \"Aaradhan public school\",\\n        \"edu__degree\": \"class XII\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n        \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n        \"edu__degree\": \"class X\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    }\\n]\\n```\\n\\nNote that the dates for Aaradhan public school and Carmel convent Sr. Sec. School are unknown, as they were not specified in the resume.\\n\\nAlso, here is the extracted information in JSON format:\\n\\n```\\n{\\n  \"CV__Education\": [\\n    {\\n      \"edu__college\": \"The LNM Institute of Information Technology\",\\n      \"edu__degree\": \"B.Tech in Computer Science\",\\n      \"edu__start_date\": \"June 2023\",\\n      \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n      \"edu__college\": \"Aaradhan public school\",\\n      \"edu__degree\": \"class XII\",\\n      \"edu__start_date\": \"unknown\",\\n      \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n      \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n      \"edu__degree\": \"class X\",\\n      \"edu__start_date\": \"unknown\",\\n      \"edu__end_date\": \"unknown\"\\n    }\\n  ]\\n}'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    response_content = invoke_LLM(\n",
    "        llm,\n",
    "        documents,\n",
    "        resume_sections=[\n",
    "            \"CV__Education\"\n",
    "        ],\n",
    "        info_message=\"Extract and evaluate education section...\",\n",
    "        language=ASSISTANT_LANGUAGE,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Load response_content into json dictionary\n",
    "        Education_Language_sections = json.loads(response_content, strict=False)\n",
    "    except Exception as e:\n",
    "        print(\"[ERROR] json.loads returns error:\", e)\n",
    "        Education_Language_sections = {}\n",
    "        \n",
    "except Exception as error:\n",
    "    print(\"[ERROR]:\", error)\n",
    "    Education_Language_sections = {}\n",
    "\n",
    "# Education_Language_sections\n",
    "response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CV__Education': '{\\n      \"edu__college\": \"The LNM Institute of Information Technology\",\\n      \"edu__degree\": \"B.Tech in Computer Science\",\\n      \"edu__start_date\": \"June 2023\",\\n      \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n      \"edu__college\": \"Aaradhan public school\",\\n      \"edu__degree\": \"class XII\",\\n      \"edu__start_date\": \"unknown\",\\n      \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n      \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n      \"edu__degree\": \"class X\",\\n      \"edu__start_date\": \"unknown',\n",
       " 'Education__evaluation': {'score__edu': 'u__college\": \"The LNM Institute of Information Technology\",\\n        \"edu__degree\": \"B.Tech in Computer Science\",\\n        \"edu__start_date\": \"June 2023\",\\n        \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n        \"edu__college\": \"Aaradhan public school\",\\n        \"edu__degree\": \"class XII\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n        \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n        \"edu__degree\": \"class X\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    }\\n]\\n```\\n\\nNote that the dates for Aaradhan public school and Carmel convent Sr. Sec. School are unknown, as they were not specified in the resume.\\n\\nAlso, here is the extracted information in JSON format:\\n\\n```\\n{\\n  \"CV__Education\": [\\n    {\\n      \"edu__college\": \"The LNM Institute of Information Technology\",\\n      \"edu__degree\": \"B.Tech in Computer Science\",\\n      \"edu__start_date\": \"June 2023\",\\n      \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n      \"edu__college\": \"Aaradhan public school\",\\n      \"edu__degree\": \"class XII\",\\n      \"edu__start_date\": \"unknown\",\\n      \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n      \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n      \"edu__degree\": \"class X\",\\n      \"edu__start_date\": \"unknown\"',\n",
       "  'evaluation__edu': 'lege\": \"The LNM Institute of Information Technology\",\\n        \"edu__degree\": \"B.Tech in Computer Science\",\\n        \"edu__start_date\": \"June 2023\",\\n        \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n        \"edu__college\": \"Aaradhan public school\",\\n        \"edu__degree\": \"class XII\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n        \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n        \"edu__degree\": \"class X\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    }\\n]\\n```\\n\\nNote that the dates for Aaradhan public school and Carmel convent Sr. Sec. School are unknown, as they were not specified in the resume.\\n\\nAlso, here is the extracted information in JSON format:\\n\\n```\\n{\\n  \"CV__Education\": [\\n    {\\n      \"edu__college\": \"The LNM Institute of Information Technology\",\\n      \"edu__degree\": \"B.Tech in Computer Science\",\\n      \"edu__start_date\": \"June 2023\",\\n      \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n      \"edu__college\": \"Aaradhan public school\",\\n      \"edu__degree\": \"class XII\",\\n      \"edu__start_date\": \"unknown\",\\n      \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n      \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n      \"edu__degree\": \"class X\",\\n      \"edu__start_date\": \"unknown'},\n",
       " 'CV__Languages': 'ollege\": \"The LNM Institute of Information Technology\",\\n        \"edu__degree\": \"B.Tech in Computer Science\",\\n        \"edu__start_date\": \"June 2023\",\\n        \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n        \"edu__college\": \"Aaradhan public school\",\\n        \"edu__degree\": \"class XII\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n        \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n        \"edu__degree\": \"class X\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    }\\n]\\n```\\n\\nNote that the dates for Aaradhan public school and Carmel convent Sr. Sec. School are unknown, as they were not specified in the resume.\\n\\nAlso, here is the extracted information in JSON format:\\n\\n```\\n{\\n  \"CV__Education\": [\\n    {\\n      \"edu__college\": \"The LNM Institute of Information Technology\",\\n      \"edu__degree\": \"B.Tech in Computer Science\",\\n      \"edu__start_date\": \"June 2023\",\\n      \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n      \"edu__college\": \"Aaradhan public school\",\\n      \"edu__degree\": \"class XII\",\\n      \"edu__start_date\": \"unknown\",\\n      \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n      \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n      \"edu__degree\": \"class X\",\\n      \"edu__start_date\": \"unknown',\n",
       " 'Languages__evaluation': {'score__language': 'llege\": \"The LNM Institute of Information Technology\",\\n        \"edu__degree\": \"B.Tech in Computer Science\",\\n        \"edu__start_date\": \"June 2023\",\\n        \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n        \"edu__college\": \"Aaradhan public school\",\\n        \"edu__degree\": \"class XII\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n        \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n        \"edu__degree\": \"class X\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    }\\n]\\n```\\n\\nNote that the dates for Aaradhan public school and Carmel convent Sr. Sec. School are unknown, as they were not specified in the resume.\\n\\nAlso, here is the extracted information in JSON format:\\n\\n```\\n{\\n  \"CV__Education\": [\\n    {\\n      \"edu__college\": \"The LNM Institute of Information Technology\",\\n      \"edu__degree\": \"B.Tech in Computer Science\",\\n      \"edu__start_date\": \"June 2023\",\\n      \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n      \"edu__college\": \"Aaradhan public school\",\\n      \"edu__degree\": \"class XII\",\\n      \"edu__start_date\": \"unknown\",\\n      \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n      \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n      \"edu__degree\": \"class X\",\\n      \"edu__start_date\": \"unknown\"',\n",
       "  'evaluation__language': ': \"The LNM Institute of Information Technology\",\\n        \"edu__degree\": \"B.Tech in Computer Science\",\\n        \"edu__start_date\": \"June 2023\",\\n        \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n        \"edu__college\": \"Aaradhan public school\",\\n        \"edu__degree\": \"class XII\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n        \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n        \"edu__degree\": \"class X\",\\n        \"edu__start_date\": \"unknown\",\\n        \"edu__end_date\": \"unknown\"\\n    }\\n]\\n```\\n\\nNote that the dates for Aaradhan public school and Carmel convent Sr. Sec. School are unknown, as they were not specified in the resume.\\n\\nAlso, here is the extracted information in JSON format:\\n\\n```\\n{\\n  \"CV__Education\": [\\n    {\\n      \"edu__college\": \"The LNM Institute of Information Technology\",\\n      \"edu__degree\": \"B.Tech in Computer Science\",\\n      \"edu__start_date\": \"June 2023\",\\n      \"edu__end_date\": \"July 2023\"\\n    },\\n    {\\n      \"edu__college\": \"Aaradhan public school\",\\n      \"edu__degree\": \"class XII\",\\n      \"edu__start_date\": \"unknown\",\\n      \"edu__end_date\": \"unknown\"\\n    },\\n    {\\n      \"edu__college\": \"Carmel convent Sr. Sec. School\",\\n      \"edu__degree\": \"class X\",\\n      \"edu__start_date\": \"unknown\",\\n      \"edu__end_date\": \"unknown\"\\n    }'}}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fields = ['CV__Education',\n",
    "               {'Education__evaluation':['score__edu','evaluation__edu']},\n",
    "               'CV__Languages',\n",
    "               {'Languages__evaluation':['score__language','evaluation__language']},\n",
    "              ]\n",
    "\n",
    "list_rfind = [\",\\n\",\",\\n\",\",\\n\",\",\\n\",\",\\n\",\",\\n\",\",\\n\",\"\\n\"] \n",
    "list_exclude_first_car = [True,True,False,True,True,True,False,True] \n",
    "\n",
    "Education_Language_sections = ResponseContent_Parser(response_content,list_fields,list_rfind,list_exclude_first_car)\n",
    "Education_Language_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_list_of_dicts(text,dict_keys):\n",
    "    \"\"\"Convert text to a python list of dicts.\n",
    "    Parameters:\n",
    "     - text: string containing a list of dicts\n",
    "     - dict_keys (list): the keys of the dictionary which will be returned.\n",
    "    Output:\n",
    "     - list_of_dicts (list): the list of dicts to return.\n",
    "     \"\"\"\n",
    "    list_of_dicts = []\n",
    "\n",
    "    if text!=\"\": # if non-empty list\n",
    "        text_splitted = text.split(\"},\\n\")\n",
    "        dict_keys.append(None)\n",
    "        \n",
    "        for i in range(len(text_splitted)):\n",
    "            dict_i = {}    \n",
    "            \n",
    "            for j in range(len(dict_keys)-1):\n",
    "                key_value = extract_from_text(text_splitted[i],f\"\\\"{dict_keys[j]}\\\": \",f\"\\\"{dict_keys[j+1]}\\\": \")\n",
    "                key_value = key_value[:key_value.rfind(\",\\n\")].strip()[1:-1]      \n",
    "                dict_i[dict_keys[j]] = key_value    \n",
    "        \n",
    "            list_of_dicts.append(dict_i) # add the dict to the list.\n",
    "        \n",
    "    return list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = Education_Language_sections['CV__Languages']\n",
    "Education_Language_sections['CV__Languages'] = convert_text_to_list_of_dicts(\n",
    "    text = languages[languages.find('[')+1:languages.rfind(\"]\")].strip(),\n",
    "    dict_keys = ['spoken__language','language__fluency']\n",
    ")\n",
    "Education_Language_sections['CV__Languages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'edu__college': 'The LNM Institute of Information Technology',\n",
       "  'edu__degree': 'B.Tech in Computer Science',\n",
       "  'edu__start_date': 'June 2023',\n",
       "  'edu__end_date': 'July 2023'},\n",
       " {'edu__college': 'Aaradhan public school',\n",
       "  'edu__degree': 'class XII',\n",
       "  'edu__start_date': 'unknown',\n",
       "  'edu__end_date': 'unknown'},\n",
       " {'edu__college': 'Carmel convent Sr. Sec. School',\n",
       "  'edu__degree': 'class X',\n",
       "  'edu__start_date': 'unk',\n",
       "  'edu__end_date': '_college\": \"Carmel convent Sr. Sec. School\",\\n      \"edu__degree\": \"class X'}]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education = Education_Language_sections['CV__Education']\n",
    "Education_Language_sections['CV__Education'] = convert_text_to_list_of_dicts(\n",
    "    text = education[education.find('[')+1:education.rfind(\"]\")].strip(),\n",
    "    dict_keys = ['edu__college','edu__degree','edu__start_date','edu__end_date']\n",
    ")\n",
    "Education_Language_sections['CV__Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Education_Language(llm, documents):\n",
    "    \"\"\"Extract and evaluate education and language sections.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response_content = invoke_LLM(\n",
    "            llm,\n",
    "            documents,\n",
    "            resume_sections=[\n",
    "                \"CV__Education\",\n",
    "                \"Education__evaluation\",\n",
    "                \"CV__Languages\",\n",
    "                \"Languages__evaluation\",\n",
    "            ],\n",
    "            info_message=\"Extract and evaluate education and language sections...\",\n",
    "            language=ASSISTANT_LANGUAGE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # Load response_content into json dictionary\n",
    "            Education_Language_sections = json.loads(response_content, strict=False)\n",
    "        except Exception as e:\n",
    "            print(\"[ERROR] json.loads returns error:\", e)\n",
    "            print(\"\\n['INFO'] Parse response content...\\n\")\n",
    "\n",
    "            list_fields = [\n",
    "                \"CV__Education\",\n",
    "                {\"Education__evaluation\": [\"score__edu\", \"evaluation__edu\"]},\n",
    "                \"CV__Languages\",\n",
    "                {\"Languages__evaluation\": [\"score__language\", \"evaluation__language\"]},\n",
    "            ]\n",
    "\n",
    "            list_rfind = [\",\\n\", \",\\n\", \",\\n\", \",\\n\", \",\\n\", \",\\n\", \",\\n\", \"\\n\"]\n",
    "            list_exclude_first_car = [True, True, False, True, True, True, False, True]\n",
    "\n",
    "            Education_Language_sections = ResponseContent_Parser(response_content, list_fields, list_rfind, list_exclude_first_car)\n",
    "\n",
    "            # Convert scores to int\n",
    "            try:\n",
    "                Education_Language_sections[\"Education__evaluation\"][\"score__edu\"] = int(\n",
    "                    Education_Language_sections[\"Education__evaluation\"][\"score__edu\"]\n",
    "                )\n",
    "            except:\n",
    "                Education_Language_sections[\"Education__evaluation\"][\"score__edu\"] = -1\n",
    "                \n",
    "            try:\n",
    "                Education_Language_sections[\"Languages__evaluation\"][\"score__language\"] = int(\n",
    "                    Education_Language_sections[\"Languages__evaluation\"][\"score__language\"]\n",
    "                )\n",
    "            except:\n",
    "                Education_Language_sections[\"Languages__evaluation\"][\"score__language\"] = -1\n",
    "\n",
    "            # Split languages and educational texts into a Python list of dict\n",
    "            languages = Education_Language_sections[\"CV__Languages\"]\n",
    "            Education_Language_sections[\"CV__Languages\"] = (\n",
    "                convert_text_to_list_of_dicts(\n",
    "                    text=languages[\n",
    "                        languages.find(\"[\") + 1 : languages.rfind(\"]\")\n",
    "                    ].strip(),\n",
    "                    dict_keys=[\"spoken__language\", \"language__fluency\"],\n",
    "                )\n",
    "            )\n",
    "            education = Education_Language_sections[\"CV__Education\"]\n",
    "            Education_Language_sections[\"CV__Education\"] = (\n",
    "                convert_text_to_list_of_dicts(\n",
    "                    text=education[\n",
    "                        education.find(\"[\") + 1 : education.rfind(\"]\")\n",
    "                    ].strip(),\n",
    "                    dict_keys=[\n",
    "                        \"edu__college\",\n",
    "                        \"edu__degree\",\n",
    "                        \"edu__start_date\",\n",
    "                        \"edu__end_date\",\n",
    "                    ],\n",
    "                )\n",
    "            )\n",
    "    except Exception as exception:\n",
    "        print(f\"[Error] {exception}\")\n",
    "        Education_Language_sections = {\n",
    "            \"CV__Education\": [],\n",
    "            \"Education__evaluation\": {\n",
    "                \"score__edu\": -1, \n",
    "                \"evaluation__edu\": \"unknown\"\n",
    "            },\n",
    "            \"CV__Languages\": [],\n",
    "            \"Languages__evaluation\": {\n",
    "                \"score__language\": -1,\n",
    "                \"evaluation__language\": \"unknown\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    return Education_Language_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**20:53:25** \tExtract and evaluate education and language sections...\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 3min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CV__Education': [{'edu__college': 'The LNM Institute of Information Technology',\n",
       "   'edu__degree': 'B.Tech in Computer Science, GPA : 7.63/10',\n",
       "   'edu__start_date': 'June 2023',\n",
       "   'edu__end_date': 'July 2023'},\n",
       "  {'edu__college': 'Aaradhan public school',\n",
       "   'edu__degree': 'class XII, Percentage : 93/100',\n",
       "   'edu__start_date': 'unknown',\n",
       "   'edu__end_date': 'unknown'},\n",
       "  {'edu__college': 'Carmel convent Sr. Sec. School',\n",
       "   'edu__degree': 'class X, Percentage : 93/100',\n",
       "   'edu__start_date': 'unknown',\n",
       "   'edu__end_date': 'unknown'}],\n",
       " 'Education__evaluation': {'score__edu': 80,\n",
       "  'evaluation__edu': \"The education section is well-structured and provides a clear overview of the candidate's academic background. However, it would be more effective if the achievements were highlighted in a separate section or with more emphasis. Overall, the section is satisfactory.\"},\n",
       " 'CV__Languages': [{'spoken__language': 'Python',\n",
       "   'language__fluency': 'unknown'},\n",
       "  {'spoken__language': 'C/C++', 'language__fluency': 'unknown'},\n",
       "  {'spoken__language': 'SQL', 'language__fluency': 'unknown'},\n",
       "  {'spoken__language': 'HTML', 'language__fluency': 'unknown'},\n",
       "  {'spoken__language': 'CSS', 'language__fluency': 'unknown'},\n",
       "  {'spoken__language': 'Java', 'language__fluency': 'unknown'}],\n",
       " 'Languages__evaluation': {'score__language': 60,\n",
       "  'evaluation__language': \"The language section is incomplete and does not provide a clear picture of the candidate's proficiency in various languages. It would be more effective if the fluency level was mentioned for each language.\"}}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Education_Language_sections = Extract_Education_Language(llm,documents)\n",
    "Education_Language_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Skills_and_Certifications(llm, documents):\n",
    "    \"\"\"Extract Skills and certifications and evaluate these sections.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response_content = invoke_LLM(\n",
    "            llm,\n",
    "            documents,\n",
    "            resume_sections=[\"candidate__skills\",\"Skills__evaluation\",\"CV__Certifications\",\"Certif__evaluation\"],\n",
    "            info_message=\"Extract and evaluate the skills and certifications...\",\n",
    "            language=ASSISTANT_LANGUAGE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # Load response_content into json dictionary\n",
    "            SKILLS_and_CERTIF = json.loads(response_content, strict=False)\n",
    "        except Exception as e:\n",
    "            print(\"[ERROR] json.loads returns error:\", e)\n",
    "            print(\"\\n['INFO'] Parse response content...\\n\")\n",
    "\n",
    "            skills = extract_from_text(response_content,\"\\\"candidate__skills\\\": \", \"\\\"Skills__evaluation\\\":\")\n",
    "            skills = skills.replace(\"\\n  \",\"\\n\").replace(\"],\\n\",\"\").replace(\"[\\n\",\"\")\n",
    "            score_skills = extract_from_text(response_content,\"\\\"score__skills\\\": \", \"\\\"evaluation__skills\\\":\")\n",
    "            evaluation_skills = extract_from_text(response_content,\"\\\"evaluation__skills\\\": \", \"\\\"CV__Certifications\\\":\")\n",
    "            \n",
    "            certif_text = extract_from_text(response_content,\"\\\"CV__Certifications\\\": \", \"\\\"Certif__evaluation\\\":\")\n",
    "            certif_score = extract_from_text(response_content,\"\\\"score__certif\\\": \", \"\\\"evaluation__certif\\\":\")\n",
    "            certif_eval = extract_from_text(response_content,\"\\\"evaluation__certif\\\": \", None)\n",
    "\n",
    "\n",
    "            # Create the dictionary\n",
    "            SKILLS_and_CERTIF = {}\n",
    "            SKILLS_and_CERTIF[\"candidate__skills\"] = [skill.strip()[1:-1] for skill in skills.split(\",\\n\")]  \n",
    "            \n",
    "            # Convert the score to int\n",
    "            try:\n",
    "                score_skills_int = int(score_skills[0 : score_skills.rfind(\",\\n\")])\n",
    "            except:\n",
    "                score_skills_int = -1\n",
    "                \n",
    "            SKILLS_and_CERTIF[\"Skills__evaluation\"] = {\n",
    "                \"score__skills\": score_skills_int,\n",
    "                \"evaluation__skills\": evaluation_skills[: evaluation_skills.rfind(\"}\\n\")].strip()[1:-1],\n",
    "            }\n",
    "\n",
    "            # Convert text to list of dictionaries\n",
    "            list_certifs = convert_text_to_list_of_dicts(\n",
    "                text=certif_text[certif_text.find(\"[\") + 1 : certif_text.rfind(\"]\")].strip(),  \n",
    "                dict_keys=[\n",
    "                    \"certif__title\",\n",
    "                    \"certif__organization\",\n",
    "                    \"certif__date\",\n",
    "                    \"certif__expiry_date\",\n",
    "                    \"certif__details\",\n",
    "                ],\n",
    "            )\n",
    "            SKILLS_and_CERTIF[\"CV__Certifications\"] = list_certifs\n",
    "            try:\n",
    "                certif_score_int = int(certif_score[0 : certif_score.rfind(\",\\n\")])\n",
    "            except:\n",
    "                certif_score_int = -1\n",
    "            SKILLS_and_CERTIF[\"Certif__evaluation\"] = {\n",
    "                \"score__certif\": certif_score_int,\n",
    "                \"evaluation__certif\": certif_eval[: certif_eval.rfind(\"}\\n\")].strip()[1:-1],\n",
    "            }\n",
    "\n",
    "    except Exception as exception:\n",
    "        SKILLS_and_CERTIF = {\n",
    "            \"candidate__skills\": [],\n",
    "            \"Skills__evaluation\": {\n",
    "                \"score__skills\": -1,\n",
    "                \"evaluation__skills\": \"unknown\",\n",
    "            },\n",
    "            \"CV__Certifications\": [],\n",
    "            \"Certif__evaluation\": {\n",
    "                \"score__certif\": -1,\n",
    "                \"evaluation__certif\": \"unknown\",\n",
    "            },\n",
    "        }\n",
    "        print(f\"[Error] {exception}\")\n",
    "\n",
    "    return SKILLS_and_CERTIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**21:02:59** \tExtract and evaluate the skills and certifications...\n",
      "[ERROR] json.loads returns error: Extra data: line 5 column 1 (char 234)\n",
      "\n",
      "['INFO'] Parse response content...\n",
      "\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 9min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'candidate__skills': [' 8',\n",
       "  'evaluation_skills\": \"The skills section is well-structured and easy to read. However, it would be more effective if the candidate provided specific examples or projects that demonstrate their skills.\"\\n}\\n```\\n\\n**CV Certifications**\\n\\n* Certificate 1:\\n\\t+ Title: Volunteer Engagement Executive\\n\\t+ Organization: BloodConnect Jaipur\\n\\t+ Date: unknown\\n\\t+ Expiry date: unknown\\n\\t+ Details: LOR/Certificate for performing social work in making India blood sufficient.\\n* Certificate 2:\\n\\t+ Title: IBM Data Analysis\\n\\t+ Organization: IBM, Coursera\\n\\t+ Date: unknown\\n\\t+ Expiry date: unknown\\n\\t+ Details: For completing IBM data Analyst Course\\n* Certificate 3:\\n\\t+ Title: Automatic Birthday Generation App\\n\\t+ Organization: LNMIIT, Jaipur\\n\\t+ Date: unknown\\n\\t+ Expiry date: unknown\\n\\t+ Details: Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\\n\\n```json\\n  {\\n      \"certif_title\": \"Volunteer Engagement Executive',\n",
       "  'certif_organization\": \"BloodConnect Jaipur',\n",
       "  'certif_date\": \"unknown',\n",
       "  'certif_expiry_date\": \"unknown',\n",
       "  'certif_details\": \"LOR/Certificate for performing social work in making India blood sufficient.\"\\n  ',\n",
       "  '\\n      \"certif_title\": \"IBM Data Analysis',\n",
       "  'certif_organization\": \"IBM, Coursera',\n",
       "  'certif_date\": \"unknown',\n",
       "  'certif_expiry_date\": \"unknown',\n",
       "  'certif_details\": \"For completing IBM data Analyst Course\"\\n  ',\n",
       "  '\\n      \"certif_title\": \"Automatic Birthday Generation App',\n",
       "  'certif_organization\": \"LNMIIT, Jaipur',\n",
       "  'certif_date\": \"unknown',\n",
       "  'certif_expiry_date\": \"unknown',\n",
       "  'certif_details\": \"Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\"\\n  }\\n]\\n```\\n\\n**Certif Evaluation**\\n\\n* Score: 70\\n* The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\\n* The certifications listed are relevant to the field of computer science and data analysis.\\n\\n```json\\n{\\n  \"score_certif\": 7',\n",
       "  'evaluation_certif\": \"The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\"\\n}\\n```\\n\\n**Final Output**\\n\\n```json\\n{\\n  \"candidate_skills\":       {\\n          \"soft_skills\": [          \"hard_skills\":               \"Python',\n",
       "  'C/C++',\n",
       "  'SQL',\n",
       "  'HTML',\n",
       "  'CSS',\n",
       "  'Java',\n",
       "  'PyTorch',\n",
       "  'TensorFlow',\n",
       "  'Keras',\n",
       "  'HuggingFace',\n",
       "  'Transformers',\n",
       "  'NLTK',\n",
       "  'Spacy',\n",
       "  'Power BI',\n",
       "  'Git',\n",
       "  'Docker',\n",
       "  'Postman',\n",
       "  'Data Structures',\n",
       "  'SOLID Principles',\n",
       "  'Design Patterns',\n",
       "  'Multiagent systems',\n",
       "  'Machine learning',\n",
       "  'Deep learning',\n",
       "  'Reinforcement learning',\n",
       "  'Data Science\"\\n          ]\\n      }\\n    \"skills_evaluation\": {\\n      \"score_skills\": 8',\n",
       "  'evaluation_skills\": \"The skills section is well-structured and easy to read. However, it would be more effective if the candidate provided specific examples or projects that demonstrate their skills.\"\\n  ',\n",
       "  'cv_certifications\":       {\\n          \"certif_title\": \"Volunteer Engagement Executive',\n",
       "  'certif_organization\": \"BloodConnect Jaipur',\n",
       "  'certif_date\": \"unknown',\n",
       "  'certif_expiry_date\": \"unknown',\n",
       "  'certif_details\": \"LOR/Certificate for performing social work in making India blood sufficient.\"\\n      ',\n",
       "  '\\n          \"certif_title\": \"IBM Data Analysis',\n",
       "  'certif_organization\": \"IBM, Coursera',\n",
       "  'certif_date\": \"unknown',\n",
       "  'certif_expiry_date\": \"unknown',\n",
       "  'certif_details\": \"For completing IBM data Analyst Course\"\\n      ',\n",
       "  '\\n          \"certif_title\": \"Automatic Birthday Generation App',\n",
       "  'certif_organization\": \"LNMIIT, Jaipur',\n",
       "  'certif_date\": \"unknown',\n",
       "  'certif_expiry_date\": \"unknown',\n",
       "  'certif_details\": \"Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\"\\n      }\\n    \"certif_evaluation\": {\\n      \"score_certif\": 7',\n",
       "  'evaluation_certif\": \"The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\"\\n  '],\n",
       " 'Skills__evaluation': {'score__skills': -1,\n",
       "  'evaluation__skills': '0,\\n    \"evaluation_skills\": \"The skills section is well-structured and easy to read. However, it would be more effective if the candidate provided specific examples or projects that demonstrate their skills.\"\\n}\\n```\\n\\n**CV Certifications**\\n\\n* Certificate 1:\\n\\t+ Title: Volunteer Engagement Executive\\n\\t+ Organization: BloodConnect Jaipur\\n\\t+ Date: unknown\\n\\t+ Expiry date: unknown\\n\\t+ Details: LOR/Certificate for performing social work in making India blood sufficient.\\n* Certificate 2:\\n\\t+ Title: IBM Data Analysis\\n\\t+ Organization: IBM, Coursera\\n\\t+ Date: unknown\\n\\t+ Expiry date: unknown\\n\\t+ Details: For completing IBM data Analyst Course\\n* Certificate 3:\\n\\t+ Title: Automatic Birthday Generation App\\n\\t+ Organization: LNMIIT, Jaipur\\n\\t+ Date: unknown\\n\\t+ Expiry date: unknown\\n\\t+ Details: Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\\n\\n```json\\n[\\n    {\\n        \"certif_title\": \"Volunteer Engagement Executive\",\\n        \"certif_organization\": \"BloodConnect Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown\",\\n        \"certif_details\": \"LOR/Certificate for performing social work in making India blood sufficient.\"\\n    },\\n    {\\n        \"certif_title\": \"IBM Data Analysis\",\\n        \"certif_organization\": \"IBM, Coursera\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown\",\\n        \"certif_details\": \"For completing IBM data Analyst Course\"\\n    },\\n    {\\n        \"certif_title\": \"Automatic Birthday Generation App\",\\n        \"certif_organization\": \"LNMIIT, Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown\",\\n        \"certif_details\": \"Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\"\\n    }\\n]\\n```\\n\\n**Certif Evaluation**\\n\\n* Score: 70\\n* The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\\n* The certifications listed are relevant to the field of computer science and data analysis.\\n\\n```json\\n{\\n    \"score_certif\": 70,\\n    \"evaluation_certif\": \"The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\"\\n}\\n```\\n\\n**Final Output**\\n\\n```json\\n{\\n    \"candidate_skills\": [\\n        {\\n            \"soft_skills\": [],\\n            \"hard_skills\": [\\n                \"Python\",\\n                \"C/C++\",\\n                \"SQL\",\\n                \"HTML\",\\n                \"CSS\",\\n                \"Java\",\\n                \"PyTorch\",\\n                \"TensorFlow\",\\n                \"Keras\",\\n                \"HuggingFace\",\\n                \"Transformers\",\\n                \"NLTK\",\\n                \"Spacy\",\\n                \"Power BI\",\\n                \"Git\",\\n                \"Docker\",\\n                \"Postman\",\\n                \"Data Structures\",\\n                \"SOLID Principles\",\\n                \"Design Patterns\",\\n                \"Multiagent systems\",\\n                \"Machine learning\",\\n                \"Deep learning\",\\n                \"Reinforcement learning\",\\n                \"Data Science\"\\n            ]\\n        }\\n    ],\\n    \"skills_evaluation\": {\\n        \"score_skills\": 80,\\n        \"evaluation_skills\": \"The skills section is well-structured and easy to read. However, it would be more effective if the candidate provided specific examples or projects that demonstrate their skills.\"\\n    },\\n    \"cv_certifications\": [\\n        {\\n            \"certif_title\": \"Volunteer Engagement Executive\",\\n            \"certif_organization\": \"BloodConnect Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown\",\\n            \"certif_details\": \"LOR/Certificate for performing social work in making India blood sufficient.\"\\n        },\\n        {\\n            \"certif_title\": \"IBM Data Analysis\",\\n            \"certif_organization\": \"IBM, Coursera\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown\",\\n            \"certif_details\": \"For completing IBM data Analyst Course\"\\n        },\\n        {\\n            \"certif_title\": \"Automatic Birthday Generation App\",\\n            \"certif_organization\": \"LNMIIT, Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown\",\\n            \"certif_details\": \"Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\"\\n        }\\n    ],\\n    \"certif_evaluation\": {\\n        \"score_certif\": 70,\\n        \"evaluation_certif\": \"The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.'},\n",
       " 'CV__Certifications': [{'certif__title': '_title\": \"Volunteer Engagement Executive\",\\n        \"certif_organization\": \"BloodConnect Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown',\n",
       "   'certif__organization': ': \"Volunteer Engagement Executive\",\\n        \"certif_organization\": \"BloodConnect Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown',\n",
       "   'certif__date': 'f_title\": \"Volunteer Engagement Executive\",\\n        \"certif_organization\": \"BloodConnect Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown',\n",
       "   'certif__expiry_date': '\": \"Volunteer Engagement Executive\",\\n        \"certif_organization\": \"BloodConnect Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown',\n",
       "   'certif__details': 'itle\": \"Volunteer Engagement Executive\",\\n        \"certif_organization\": \"BloodConnect Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown'},\n",
       "  {'certif__title': 'rtif_title\": \"IBM Data Analysis\",\\n        \"certif_organization\": \"IBM, Coursera\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown',\n",
       "   'certif__organization': 'tle\": \"IBM Data Analysis\",\\n        \"certif_organization\": \"IBM, Coursera\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown',\n",
       "   'certif__date': 'ertif_title\": \"IBM Data Analysis\",\\n        \"certif_organization\": \"IBM, Coursera\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown',\n",
       "   'certif__expiry_date': 'itle\": \"IBM Data Analysis\",\\n        \"certif_organization\": \"IBM, Coursera\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown',\n",
       "   'certif__details': 'if_title\": \"IBM Data Analysis\",\\n        \"certif_organization\": \"IBM, Coursera\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown'},\n",
       "  {'certif__title': 'rtif_title\": \"Automatic Birthday Generation App\",\\n        \"certif_organization\": \"LNMIIT, Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown\",\\n        \"certif_details\": \"Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\"\\n    }\\n]\\n```\\n\\n**Certif Evaluation**\\n\\n* Score: 70\\n* The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\\n* The certifications listed are relevant to the field of computer science and data analysis.\\n\\n```json\\n{\\n    \"score_certif\": 70,\\n    \"evaluation_certif\": \"The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\"\\n}\\n```\\n\\n**Final Output**\\n\\n```json\\n{\\n    \"candidate_skills\": [\\n        {\\n            \"soft_skills\": [],\\n            \"hard_skills\": [\\n                \"Python\",\\n                \"C/C++\",\\n                \"SQL\",\\n                \"HTML\",\\n                \"CSS\",\\n                \"Java\",\\n                \"PyTorch\",\\n                \"TensorFlow\",\\n                \"Keras\",\\n                \"HuggingFace\",\\n                \"Transformers\",\\n                \"NLTK\",\\n                \"Spacy\",\\n                \"Power BI\",\\n                \"Git\",\\n                \"Docker\",\\n                \"Postman\",\\n                \"Data Structures\",\\n                \"SOLID Principles\",\\n                \"Design Patterns\",\\n                \"Multiagent systems\",\\n                \"Machine learning\",\\n                \"Deep learning\",\\n                \"Reinforcement learning\",\\n                \"Data Science\"\\n            ]\\n        }\\n    ],\\n    \"skills_evaluation\": {\\n        \"score_skills\": 8',\n",
       "   'certif__organization': 'tle\": \"Automatic Birthday Generation App\",\\n        \"certif_organization\": \"LNMIIT, Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown\",\\n        \"certif_details\": \"Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\"\\n    }\\n]\\n```\\n\\n**Certif Evaluation**\\n\\n* Score: 70\\n* The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\\n* The certifications listed are relevant to the field of computer science and data analysis.\\n\\n```json\\n{\\n    \"score_certif\": 70,\\n    \"evaluation_certif\": \"The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\"\\n}\\n```\\n\\n**Final Output**\\n\\n```json\\n{\\n    \"candidate_skills\": [\\n        {\\n            \"soft_skills\": [],\\n            \"hard_skills\": [\\n                \"Python\",\\n                \"C/C++\",\\n                \"SQL\",\\n                \"HTML\",\\n                \"CSS\",\\n                \"Java\",\\n                \"PyTorch\",\\n                \"TensorFlow\",\\n                \"Keras\",\\n                \"HuggingFace\",\\n                \"Transformers\",\\n                \"NLTK\",\\n                \"Spacy\",\\n                \"Power BI\",\\n                \"Git\",\\n                \"Docker\",\\n                \"Postman\",\\n                \"Data Structures\",\\n                \"SOLID Principles\",\\n                \"Design Patterns\",\\n                \"Multiagent systems\",\\n                \"Machine learning\",\\n                \"Deep learning\",\\n                \"Reinforcement learning\",\\n                \"Data Science\"\\n            ]\\n        }\\n    ],\\n    \"skills_evaluation\": {\\n        \"score_skills\": 8',\n",
       "   'certif__date': 'ertif_title\": \"Automatic Birthday Generation App\",\\n        \"certif_organization\": \"LNMIIT, Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown\",\\n        \"certif_details\": \"Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\"\\n    }\\n]\\n```\\n\\n**Certif Evaluation**\\n\\n* Score: 70\\n* The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\\n* The certifications listed are relevant to the field of computer science and data analysis.\\n\\n```json\\n{\\n    \"score_certif\": 70,\\n    \"evaluation_certif\": \"The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\"\\n}\\n```\\n\\n**Final Output**\\n\\n```json\\n{\\n    \"candidate_skills\": [\\n        {\\n            \"soft_skills\": [],\\n            \"hard_skills\": [\\n                \"Python\",\\n                \"C/C++\",\\n                \"SQL\",\\n                \"HTML\",\\n                \"CSS\",\\n                \"Java\",\\n                \"PyTorch\",\\n                \"TensorFlow\",\\n                \"Keras\",\\n                \"HuggingFace\",\\n                \"Transformers\",\\n                \"NLTK\",\\n                \"Spacy\",\\n                \"Power BI\",\\n                \"Git\",\\n                \"Docker\",\\n                \"Postman\",\\n                \"Data Structures\",\\n                \"SOLID Principles\",\\n                \"Design Patterns\",\\n                \"Multiagent systems\",\\n                \"Machine learning\",\\n                \"Deep learning\",\\n                \"Reinforcement learning\",\\n                \"Data Science\"\\n            ]\\n        }\\n    ],\\n    \"skills_evaluation\": {\\n        \"score_skills\": 8',\n",
       "   'certif__expiry_date': 'itle\": \"Automatic Birthday Generation App\",\\n        \"certif_organization\": \"LNMIIT, Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown\",\\n        \"certif_details\": \"Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\"\\n    }\\n]\\n```\\n\\n**Certif Evaluation**\\n\\n* Score: 70\\n* The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\\n* The certifications listed are relevant to the field of computer science and data analysis.\\n\\n```json\\n{\\n    \"score_certif\": 70,\\n    \"evaluation_certif\": \"The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\"\\n}\\n```\\n\\n**Final Output**\\n\\n```json\\n{\\n    \"candidate_skills\": [\\n        {\\n            \"soft_skills\": [],\\n            \"hard_skills\": [\\n                \"Python\",\\n                \"C/C++\",\\n                \"SQL\",\\n                \"HTML\",\\n                \"CSS\",\\n                \"Java\",\\n                \"PyTorch\",\\n                \"TensorFlow\",\\n                \"Keras\",\\n                \"HuggingFace\",\\n                \"Transformers\",\\n                \"NLTK\",\\n                \"Spacy\",\\n                \"Power BI\",\\n                \"Git\",\\n                \"Docker\",\\n                \"Postman\",\\n                \"Data Structures\",\\n                \"SOLID Principles\",\\n                \"Design Patterns\",\\n                \"Multiagent systems\",\\n                \"Machine learning\",\\n                \"Deep learning\",\\n                \"Reinforcement learning\",\\n                \"Data Science\"\\n            ]\\n        }\\n    ],\\n    \"skills_evaluation\": {\\n        \"score_skills\": 8',\n",
       "   'certif__details': 'if_title\": \"Automatic Birthday Generation App\",\\n        \"certif_organization\": \"LNMIIT, Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown\",\\n        \"certif_details\": \"Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\"\\n    }\\n]\\n```\\n\\n**Certif Evaluation**\\n\\n* Score: 70\\n* The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\\n* The certifications listed are relevant to the field of computer science and data analysis.\\n\\n```json\\n{\\n    \"score_certif\": 70,\\n    \"evaluation_certif\": \"The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\"\\n}\\n```\\n\\n**Final Output**\\n\\n```json\\n{\\n    \"candidate_skills\": [\\n        {\\n            \"soft_skills\": [],\\n            \"hard_skills\": [\\n                \"Python\",\\n                \"C/C++\",\\n                \"SQL\",\\n                \"HTML\",\\n                \"CSS\",\\n                \"Java\",\\n                \"PyTorch\",\\n                \"TensorFlow\",\\n                \"Keras\",\\n                \"HuggingFace\",\\n                \"Transformers\",\\n                \"NLTK\",\\n                \"Spacy\",\\n                \"Power BI\",\\n                \"Git\",\\n                \"Docker\",\\n                \"Postman\",\\n                \"Data Structures\",\\n                \"SOLID Principles\",\\n                \"Design Patterns\",\\n                \"Multiagent systems\",\\n                \"Machine learning\",\\n                \"Deep learning\",\\n                \"Reinforcement learning\",\\n                \"Data Science\"\\n            ]\\n        }\\n    ],\\n    \"skills_evaluation\": {\\n        \"score_skills\": 8'},\n",
       "  {'certif__title': 'tions\": [\\n        {\\n            \"certif_title\": \"Volunteer Engagement Executive\",\\n            \"certif_organization\": \"BloodConnect Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__organization': ' [\\n        {\\n            \"certif_title\": \"Volunteer Engagement Executive\",\\n            \"certif_organization\": \"BloodConnect Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__date': 'ations\": [\\n        {\\n            \"certif_title\": \"Volunteer Engagement Executive\",\\n            \"certif_organization\": \"BloodConnect Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__expiry_date': ': [\\n        {\\n            \"certif_title\": \"Volunteer Engagement Executive\",\\n            \"certif_organization\": \"BloodConnect Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__details': 'ons\": [\\n        {\\n            \"certif_title\": \"Volunteer Engagement Executive\",\\n            \"certif_organization\": \"BloodConnect Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown'},\n",
       "  {'certif__title': 'certif_title\": \"IBM Data Analysis\",\\n            \"certif_organization\": \"IBM, Coursera\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__organization': 'ertif_title\": \"IBM Data Analysis\",\\n            \"certif_organization\": \"IBM, Coursera\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__date': 'certif_title\": \"IBM Data Analysis\",\\n            \"certif_organization\": \"IBM, Coursera\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__expiry_date': 'certif_title\": \"IBM Data Analysis\",\\n            \"certif_organization\": \"IBM, Coursera\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__details': 'certif_title\": \"IBM Data Analysis\",\\n            \"certif_organization\": \"IBM, Coursera\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown'},\n",
       "  {'certif__title': 'certif_title\": \"Automatic Birthday Generation App\",\\n            \"certif_organization\": \"LNMIIT, Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__organization': 'ertif_title\": \"Automatic Birthday Generation App\",\\n            \"certif_organization\": \"LNMIIT, Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__date': 'certif_title\": \"Automatic Birthday Generation App\",\\n            \"certif_organization\": \"LNMIIT, Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__expiry_date': 'certif_title\": \"Automatic Birthday Generation App\",\\n            \"certif_organization\": \"LNMIIT, Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown',\n",
       "   'certif__details': 'certif_title\": \"Automatic Birthday Generation App\",\\n            \"certif_organization\": \"LNMIIT, Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown'}],\n",
       " 'Certif__evaluation': {'score__certif': -1,\n",
       "  'evaluation__certif': '0,\\n    \"evaluation_skills\": \"The skills section is well-structured and easy to read. However, it would be more effective if the candidate provided specific examples or projects that demonstrate their skills.\"\\n}\\n```\\n\\n**CV Certifications**\\n\\n* Certificate 1:\\n\\t+ Title: Volunteer Engagement Executive\\n\\t+ Organization: BloodConnect Jaipur\\n\\t+ Date: unknown\\n\\t+ Expiry date: unknown\\n\\t+ Details: LOR/Certificate for performing social work in making India blood sufficient.\\n* Certificate 2:\\n\\t+ Title: IBM Data Analysis\\n\\t+ Organization: IBM, Coursera\\n\\t+ Date: unknown\\n\\t+ Expiry date: unknown\\n\\t+ Details: For completing IBM data Analyst Course\\n* Certificate 3:\\n\\t+ Title: Automatic Birthday Generation App\\n\\t+ Organization: LNMIIT, Jaipur\\n\\t+ Date: unknown\\n\\t+ Expiry date: unknown\\n\\t+ Details: Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\\n\\n```json\\n[\\n    {\\n        \"certif_title\": \"Volunteer Engagement Executive\",\\n        \"certif_organization\": \"BloodConnect Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown\",\\n        \"certif_details\": \"LOR/Certificate for performing social work in making India blood sufficient.\"\\n    },\\n    {\\n        \"certif_title\": \"IBM Data Analysis\",\\n        \"certif_organization\": \"IBM, Coursera\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown\",\\n        \"certif_details\": \"For completing IBM data Analyst Course\"\\n    },\\n    {\\n        \"certif_title\": \"Automatic Birthday Generation App\",\\n        \"certif_organization\": \"LNMIIT, Jaipur\",\\n        \"certif_date\": \"unknown\",\\n        \"certif_expiry_date\": \"unknown\",\\n        \"certif_details\": \"Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\"\\n    }\\n]\\n```\\n\\n**Certif Evaluation**\\n\\n* Score: 70\\n* The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\\n* The certifications listed are relevant to the field of computer science and data analysis.\\n\\n```json\\n{\\n    \"score_certif\": 70,\\n    \"evaluation_certif\": \"The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.\"\\n}\\n```\\n\\n**Final Output**\\n\\n```json\\n{\\n    \"candidate_skills\": [\\n        {\\n            \"soft_skills\": [],\\n            \"hard_skills\": [\\n                \"Python\",\\n                \"C/C++\",\\n                \"SQL\",\\n                \"HTML\",\\n                \"CSS\",\\n                \"Java\",\\n                \"PyTorch\",\\n                \"TensorFlow\",\\n                \"Keras\",\\n                \"HuggingFace\",\\n                \"Transformers\",\\n                \"NLTK\",\\n                \"Spacy\",\\n                \"Power BI\",\\n                \"Git\",\\n                \"Docker\",\\n                \"Postman\",\\n                \"Data Structures\",\\n                \"SOLID Principles\",\\n                \"Design Patterns\",\\n                \"Multiagent systems\",\\n                \"Machine learning\",\\n                \"Deep learning\",\\n                \"Reinforcement learning\",\\n                \"Data Science\"\\n            ]\\n        }\\n    ],\\n    \"skills_evaluation\": {\\n        \"score_skills\": 80,\\n        \"evaluation_skills\": \"The skills section is well-structured and easy to read. However, it would be more effective if the candidate provided specific examples or projects that demonstrate their skills.\"\\n    },\\n    \"cv_certifications\": [\\n        {\\n            \"certif_title\": \"Volunteer Engagement Executive\",\\n            \"certif_organization\": \"BloodConnect Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown\",\\n            \"certif_details\": \"LOR/Certificate for performing social work in making India blood sufficient.\"\\n        },\\n        {\\n            \"certif_title\": \"IBM Data Analysis\",\\n            \"certif_organization\": \"IBM, Coursera\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown\",\\n            \"certif_details\": \"For completing IBM data Analyst Course\"\\n        },\\n        {\\n            \"certif_title\": \"Automatic Birthday Generation App\",\\n            \"certif_organization\": \"LNMIIT, Jaipur\",\\n            \"certif_date\": \"unknown\",\\n            \"certif_expiry_date\": \"unknown\",\\n            \"certif_details\": \"Received for my contributions in the Avaataran App that is deployed on LNMIIT server.\"\\n        }\\n    ],\\n    \"certif_evaluation\": {\\n        \"score_certif\": 70,\\n        \"evaluation_certif\": \"The certifications section is well-structured, but it would be more effective if the candidate provided specific dates and details about each certification.'}}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SKILLS_and_CERTIF = Extract_Skills_and_Certifications(llm,documents)\n",
    "SKILLS_and_CERTIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_PROFESSIONAL_EXPERIENCE(llm, documents):\n",
    "    \"\"\"Extract the list of work experience and projects.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response_content  = invoke_LLM(\n",
    "            llm,\n",
    "            documents,\n",
    "            resume_sections=[\"Work__experience\", \"CV__Projects\"],\n",
    "            info_message=\"Extract list of work experience and projects...\",\n",
    "            language=ASSISTANT_LANGUAGE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # Load response_content into json dictionary\n",
    "            PROFESSIONAL_EXPERIENCE = json.loads(response_content+\"}\", strict=False)\n",
    "        except Exception as e:\n",
    "            print(\"[ERROR] json.loads returns error:\", e)\n",
    "            print(\"\\n['INFO'] Parse response content...\\n\")\n",
    "            work_experiences = extract_from_text(response_content, '\"Work__experience\": ', '\"CV__Projects\":')\n",
    "            projects = extract_from_text(response_content, '\"CV__Projects\": ', None)\n",
    "\n",
    "            # Create the dictionary\n",
    "            PROFESSIONAL_EXPERIENCE = {}\n",
    "            PROFESSIONAL_EXPERIENCE[\"Work__experience\"] = convert_text_to_list_of_dicts(\n",
    "                text=work_experiences[work_experiences.find(\"[\") + 1 : work_experiences.rfind(\"]\")].strip()[1:-1],\n",
    "                dict_keys=[\"job__title\", \"job__company\", \"job__start_date\", \"job__end_date\"],\n",
    "            )\n",
    "            PROFESSIONAL_EXPERIENCE[\"CV__Projects\"] = convert_text_to_list_of_dicts(\n",
    "                text=projects[projects.find(\"[\") + 1 : projects.rfind(\"]\")].strip()[1:-1],\n",
    "                dict_keys=[\"project__title\", \"project__start_date\", \"project__end_date\"],\n",
    "            )\n",
    "        # delete 'unknown' projects and work experience\n",
    "        try:\n",
    "            for work_experience in PROFESSIONAL_EXPERIENCE[\"Work__experience\"]:\n",
    "                if work_experience[\"job__title\"] == \"unknown\":\n",
    "                    PROFESSIONAL_EXPERIENCE[\"Work__experience\"].remove(work_experience)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        try:\n",
    "            for project in PROFESSIONAL_EXPERIENCE[\"CV__Projects\"]:\n",
    "                if project[\"project__title\"] == \"unknown\":\n",
    "                    PROFESSIONAL_EXPERIENCE[\"CV__Projects\"].remove(project)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    except Exception as exception:\n",
    "        PROFESSIONAL_EXPERIENCE = {\n",
    "            \"Work__experience\": [],\n",
    "            \"CV__Projects\": []\n",
    "        }\n",
    "        print(exception)\n",
    "        \n",
    "    return PROFESSIONAL_EXPERIENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**21:12:45** \tExtract list of work experience and projects...\n",
      "[ERROR] json.loads returns error: Extra data: line 6 column 6 (char 163)\n",
      "\n",
      "['INFO'] Parse response content...\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 4min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Work__experience': [{'job__title': 'Intern',\n",
       "   'job__company': 'Agent Oriented Development | LNMIIT',\n",
       "   'job__start_date': '2023/06',\n",
       "   'job__end_date': '2023/07'},\n",
       "  {'job__title': 'B.Tech in Computer Science',\n",
       "   'job__company': 'The LNM Institute of Information Technology',\n",
       "   'job__start_date': '2021/11',\n",
       "   'job__end_date': 'Present'}],\n",
       " 'CV__Projects': [{'project__title': 'Multi class Classification Using Image transformers',\n",
       "   'project__start_date': '2024/03',\n",
       "   'project__end_date': 'unknown'},\n",
       "  {'project__title': 'Loksabha 2024 data analysis: Instagram',\n",
       "   'project__start_date': '2024/04',\n",
       "   'project__end_date': 'unknown'},\n",
       "  {'project__title': 'Anime Face Generator',\n",
       "   'project__start_date': '2024/01',\n",
       "   'project__end_date': 'unknown'},\n",
       "  {'project__title': 'ASL Convertor',\n",
       "   'project__start_date': '2023/06',\n",
       "   'project__end_date': 'unknown'}]}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "PROFESSIONAL_EXPERIENCE = Extract_PROFESSIONAL_EXPERIENCE(llm,documents)\n",
    "PROFESSIONAL_EXPERIENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_documents(query,documents,retriever):\n",
    "    \"\"\"Retreieve most relevant documents from Langchain documents using the CoherRerank retriever.\"\"\"\n",
    "\n",
    "    # 1.1. Get relevant documents using the CohereRerank retriever\n",
    "\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "    # 1.2. Keep only relevant documents where (relevance_score >= (max(relevance_scores) - 0.1))\n",
    "\n",
    "    relevance_scores = [\n",
    "        retrieved_docs[j].metadata[\"relevance_score\"]\n",
    "        for j in range(len(retrieved_docs))\n",
    "    ]\n",
    "    max_relevance_score = max(relevance_scores)\n",
    "    threshold = max_relevance_score - 0.1\n",
    "\n",
    "    relevant_doc_ids = []\n",
    "\n",
    "    for j in range(len(retrieved_docs)):\n",
    "\n",
    "        # Keep relevant documents with (relevance_score >= threshold)\n",
    "        if retrieved_docs[j].metadata[\"relevance_score\"] >= threshold:\n",
    "            relevant_doc_ids.append(retrieved_docs[j].metadata[\"doc_number\"])\n",
    "\n",
    "    # Append the next document to the most relevant document, as relevant information may be split between two documents.\n",
    "    relevant_doc_ids.append(min(relevant_doc_ids[0]+1, len(documents)-1))\n",
    "\n",
    "    relevant_doc_ids = sorted(set(relevant_doc_ids))  # Sort doc ids\n",
    "    \n",
    "    # get the most relevant documents (+ next document)\n",
    "    relevant_documents = [\n",
    "        documents[k] for k in relevant_doc_ids\n",
    "    ]  \n",
    "\n",
    "    return relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Job_Responsibilities(llm, documents, retriever, PROFESSIONAL_EXPERIENCE):\n",
    "    \"\"\"Extract job responsibilities for each job in PROFESSIONAL_EXPERIENCE.\"\"\"\n",
    "\n",
    "    now = (datetime.datetime.now()).strftime(\"%H:%M:%S\")\n",
    "    print(f\"**{now}** \\tExtract work experience responsabilities...\")\n",
    "\n",
    "    for i in range(len(PROFESSIONAL_EXPERIENCE[\"Work__experience\"])):\n",
    "        try:\n",
    "            Work_experience_i = PROFESSIONAL_EXPERIENCE[\"Work__experience\"][i]\n",
    "            print(f\"\\n\\n{i}: {Work_experience_i['job__title']}\", end=\" | \")\n",
    "\n",
    "            # 1. Query\n",
    "            query = f\"\"\"Extract from the resume delimited by triple backticks \\\n",
    "all the duties and responsabilities of the following work experience: \\\n",
    "(title = '{Work_experience_i['job__title']}'\"\"\"\n",
    "            if str(Work_experience_i[\"job__company\"]) != \"unknown\":\n",
    "                query += f\" and company = '{Work_experience_i['job__company']}'\"\n",
    "            if str(Work_experience_i[\"job__start_date\"]) != \"unknown\":\n",
    "                query += f\" and start date = '{Work_experience_i['job__start_date']}'\"\n",
    "            if str(Work_experience_i[\"job__end_date\"]) != \"unknown\":\n",
    "                query += f\" and end date = '{Work_experience_i['job__end_date']}'\"\n",
    "            query += \")\\n\"\n",
    "\n",
    "            # 2. For longer CVs (i.e. number of documents > 2), \n",
    "            # use the CohereRerank retriever to find the most relevant documents.\n",
    "            if len(documents)>2:\n",
    "                try:\n",
    "                    relevant_documents = get_relevant_documents(query, documents, retriever)\n",
    "                except Exception as err:\n",
    "                    print(f\"[ERROR] get_relevant_documents error: {err}\")\n",
    "                    relevant_documents = documents\n",
    "            else:\n",
    "                relevant_documents = documents\n",
    "                \n",
    "            print(f\"relevant docs : {len(relevant_documents)}\", end=\" | \")\n",
    "\n",
    "            # 3. Invoke the LLM            \n",
    "            prompt = (\n",
    "                query\n",
    "                + f\"\"\"Output the duties in a json dictionary with the following keys (__duty_id__,__duty__). \\\n",
    "Use this format: \"1\":\"duty\",\"2\":\"another duty\".\n",
    "Resume:\\n\\n ```{relevant_documents}```\"\"\"\n",
    "            )\n",
    "\n",
    "            print(f\"prompt tokens: {sum(tiktoken_tokens([prompt]))}\", end=\" | \")\n",
    "\n",
    "            response = llm.invoke(prompt)\n",
    "            response_content = response.content[response.content.find(\"{\") : response.content.rfind(\"}\") + 1]\n",
    "            print(f\"\"\"response tokens: {sum(tiktoken_tokens([response_content]))}\"\"\")\n",
    "\n",
    "            try:\n",
    "                # 4. Convert the response content to json dict and update work_experience\n",
    "                Work_experience_i[\"work__duties\"] = json.loads(response_content, strict=False)  \n",
    "            except Exception as e:\n",
    "                print(\"\\n[ERROR] json.loads returns error:\", e, \"\\n\\n\")\n",
    "                print(\"\\n['INFO'] Parse response content...\\n\")                \n",
    "                Work_experience_i[\"work__duties\"] = {}\n",
    "                list_duties = (\n",
    "                    response_content[response_content.find(\"{\") + 1 : response_content.rfind(\"}\")].strip().split(\",\\n\")\n",
    "                )\n",
    "                for j in range(len(list_duties)):\n",
    "                    try:\n",
    "                        Work_experience_i[\"work__duties\"][f\"{j+1}\"] = (list_duties[j].split('\":')[1].strip()[1:-1])\n",
    "                    except:\n",
    "                        Work_experience_i[\"work__duties\"][f\"{j+1}\"] = \"unknown\"\n",
    "\n",
    "        except Exception as exception:\n",
    "            print(f\"[ERROR] {exception}\")\n",
    "            Work_experience_i[\"work__duties\"] = {}          \n",
    "\n",
    "    return PROFESSIONAL_EXPERIENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**21:21:06** \tExtract work experience responsabilities...\n",
      "\n",
      "\n",
      "0: Intern | relevant docs : 1 | [ERROR] name 'tiktoken_tokens' is not defined\n",
      "\n",
      "\n",
      "1: B.Tech in Computer Science | relevant docs : 1 | [ERROR] name 'tiktoken_tokens' is not defined\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 13.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'job__title': 'Intern',\n",
       "  'job__company': 'Agent Oriented Development | LNMIIT',\n",
       "  'job__start_date': '2023/06',\n",
       "  'job__end_date': '2023/07',\n",
       "  'work__duties': {}},\n",
       " {'job__title': 'B.Tech in Computer Science',\n",
       "  'job__company': 'The LNM Institute of Information Technology',\n",
       "  'job__start_date': '2021/11',\n",
       "  'job__end_date': 'Present',\n",
       "  'work__duties': {}}]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "PROFESSIONAL_EXPERIENCE = Extract_Job_Responsibilities(llm,documents,retriever,PROFESSIONAL_EXPERIENCE)\n",
    "PROFESSIONAL_EXPERIENCE['Work__experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Project_Details(llm, documents, retriever, PROFESSIONAL_EXPERIENCE):\n",
    "    \"\"\"Extract project details for each project in PROFESSIONAL_EXPERIENCE.\"\"\"\n",
    "\n",
    "    now = (datetime.datetime.now()).strftime(\"%H:%M:%S\")\n",
    "    print(f\"**{now}** \\tExtract project details...\")\n",
    "\n",
    "    for i in range(len(PROFESSIONAL_EXPERIENCE[\"CV__Projects\"])):\n",
    "        try:\n",
    "            project_i = PROFESSIONAL_EXPERIENCE[\"CV__Projects\"][i]\n",
    "            print(f\"{i}: {project_i['project__title']}\", end=\" | \")\n",
    "\n",
    "            # 1. Extract relevant documents\n",
    "            query = f\"\"\"Extract from the resume (delimited by triple backticks) what is listed about the following project: \\\n",
    "(project title = '{project_i['project__title']}'\"\"\"\n",
    "            if str(project_i[\"project__start_date\"]) != \"unknown\":\n",
    "                query += f\" and start date = '{project_i['project__start_date']}'\"\n",
    "            if str(project_i[\"project__end_date\"]) != \"unknown\":\n",
    "                query += f\" and end date = '{project_i['project__end_date']}'\"\n",
    "            query += \")\"\n",
    "\n",
    "            if len(documents)>2:\n",
    "                try:\n",
    "                    relevant_documents = get_relevant_documents(query, documents, retriever)\n",
    "                except Exception as err:\n",
    "                    print(f\"[ERROR] get_relevant_documents error: {err}\")\n",
    "                    relevant_documents = documents\n",
    "            else:\n",
    "                relevant_documents = documents\n",
    "                \n",
    "            print(f\"relevant docs : {len(relevant_documents)}\", end=\" | \")\n",
    "\n",
    "            # 2. Invoke the LLM\n",
    "\n",
    "            prompt = (query + f\"\"\"Format the extracted text into a string (with bullet points).\n",
    "Resume:\\n\\n ```{relevant_documents}```\"\"\" )\n",
    "\n",
    "            response = llm.invoke(prompt)\n",
    "\n",
    "            response_content = response.content\n",
    "            project_i[\"project__description\"] = response_content\n",
    "\n",
    "        except Exception as exception:\n",
    "            project_i[\"project__description\"] = \"unknown\"\n",
    "            print(exception)\n",
    "\n",
    "    return PROFESSIONAL_EXPERIENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**21:28:11** \tExtract project details...\n",
      "0: Multi class Classification Using Image transformers | relevant docs : 1 | 1: Loksabha 2024 data analysis: Instagram | relevant docs : 1 | 2: Anime Face Generator | relevant docs : 1 | 3: ASL Convertor | relevant docs : 1 | CPU times: total: 93.8 ms\n",
      "Wall time: 3min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'project__title': 'Multi class Classification Using Image transformers',\n",
       "  'project__start_date': '2024/03',\n",
       "  'project__end_date': 'unknown',\n",
       "  'project__description': 'Here is the extracted text about the project \"Multi class Classification Using Image transformers\" in a string with bullet points:\\n\\n* Project: Multi class Classification Using Image transformers\\n* Start Date: March 2024\\n* Details:\\n\\t+ An image classification model built with a transformer encoder only architecture.\\n\\t+ Developed a PyTorch model, achieving 75% accuracy; improved to 95% with transfer learning and fine-tuning a pre-trained vision transformer.'},\n",
       " {'project__title': 'Loksabha 2024 data analysis: Instagram',\n",
       "  'project__start_date': '2024/04',\n",
       "  'project__end_date': 'unknown',\n",
       "  'project__description': 'Here is the extracted text about the project \"Loksabha 2024 data analysis: Instagram\" in a string with bullet points:\\n\\n* Project Title: Loksabha 2024 data analysis: Instagram\\n* Start Date: April 2024\\n* Technologies Used:\\n\\t+ Python\\n\\t+ Data Gathering\\n\\t+ Data Visualizing\\n\\t+ Data Inferencing\\n* Description:\\n\\t- Research on Instagram data of Loksabha 2024\\n\\t- Data is fetched from meta’s crowdtangle API and is analysed using Unsupervised learning algorithms like HDBSCAN, topic modelling using LDA and BertTopic'},\n",
       " {'project__title': 'Anime Face Generator',\n",
       "  'project__start_date': '2024/01',\n",
       "  'project__end_date': 'unknown',\n",
       "  'project__description': 'Here is the extracted text about the \"Anime Face Generator\" project, formatted into a string with bullet points:\\n\\n* Project: Anime Face Generator\\n* Start Date: Jan 2024\\n* Details:\\n\\t+ Used Generative Adversarial Networks (GAN) to create a generative model\\n\\t+ The Model takes input a value and corresponding to that generates a face image of an anime Character'},\n",
       " {'project__title': 'ASL Convertor',\n",
       "  'project__start_date': '2023/06',\n",
       "  'project__end_date': 'unknown',\n",
       "  'project__description': 'Here is the extracted text about the project \"ASL Convertor\" in a string with bullet points:\\n\\n* Project: ASL Convertor\\n* Start Date: June 2023\\n* Technologies Used:\\n\\t+ Python\\n\\t+ Data Analysis\\n\\t+ Machine Learning\\n* Achievements:\\n\\t- Explored multiple algorithms to classify and compare the American Sign Language dataset from Kaggle, achieving accuracies from 74% to 95%.'}]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "PROFESSIONAL_EXPERIENCE = Extract_Project_Details(llm,documents,retriever,PROFESSIONAL_EXPERIENCE)\n",
    "PROFESSIONAL_EXPERIENCE['CV__Projects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
